{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " ADML_Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pbJKViiuFR93",
        "Szlc33XGndq6",
        "UPP4ZSl1kLuB",
        "U0JLRvgGrjSL",
        "AvBGOiJsroj-",
        "90vCzVPCHGrH",
        "QW3oGRRzFeuZ",
        "VatgD8XhF5nh",
        "lSIJwd7jGJqn",
        "U1tdouV-f6Jx",
        "Yi-fi5x8HavF",
        "afUY7CuYGpOh",
        "C0Aj0Gftk_Q7",
        "mEurcMLEHamI",
        "J4nLq012IAQg",
        "A0cur5QFIRqT",
        "o6VPpN80lL5A",
        "XVdURyplIWJJ",
        "d3uYnKBfq2-A",
        "uQv5FwqKq-Zb",
        "bqgyez9FAWmQ",
        "vnROA09gGi9c",
        "RXJViMLPfwL0",
        "L8FbGSwdKkaS",
        "FRz-nKUXK-_a",
        "oZpAofx3Luqs",
        "jYzzqz0OL-b3",
        "LwBcnQ2SMDBi",
        "paoOO20WMOP4",
        "MQt0Nf08MVyk",
        "45c4XFW7MbBP",
        "09o0-oqCkcOC",
        "TSB8Ss1IMocD",
        "fENh95nzM9O-",
        "9iXfRyGjkwvY",
        "TvDNPPJoNbIH",
        "466oXafMCBAn",
        "1G3al-oYCHNM",
        "803RQ3FJCRHD",
        "K1FU5DgkDlGU",
        "u8nFSL-Almjx",
        "AVAM4pogKRba",
        "hUFVBq8EKV-1",
        "TY-uCASvK0xZ",
        "tPC2srGHlwR4",
        "FfnblnofYCAT",
        "_PFu5GyjYGMi",
        "ZmVUs-Fxl2W1",
        "jhpWNSsvaLTQ",
        "ZOCJUliZbIW-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "Szlc33XGndq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jddKUaxrkIxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.models import vgg16\n",
        "from torchvision.models import resnet50\n",
        "import torch.optim as optim\n",
        "\n",
        "!pip install adversarial-robustness-toolbox\n",
        "from art.attacks.evasion import DeepFool as DeepFool_\n",
        "from art.attacks.evasion import CarliniL2Method\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "import natsort\n",
        "from natsort import natsorted\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "bQDbZx3MkRlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FGSM & PGD\n",
        "!pip install -qq -e git+http://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "import sys\n",
        "sys.path.append('/content/src/cleverhans')\n",
        "import cleverhans\n",
        "\n",
        "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
        "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n"
      ],
      "metadata": {
        "id": "1WvntRKlkbTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox\n",
        "from art.attacks.evasion import DeepFool , SaliencyMapMethod, CarliniL2Method\n",
        "from art.estimators.classification import PyTorchClassifier"
      ],
      "metadata": {
        "id": "rNBJ0k8-kk0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loader"
      ],
      "metadata": {
        "id": "UPP4ZSl1kLuB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9P5F_kIok4P"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip\n",
        "!wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZlADcuRb08"
      },
      "source": [
        "!unzip 'BelgiumTSC_Training.zip'\n",
        "!unzip 'BelgiumTSC_Testing.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Class"
      ],
      "metadata": {
        "id": "U0JLRvgGrjSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BL_Dataset(Dataset):\n",
        "    def __init__(self, Data, transform=None):\n",
        "        if Data == \"train\":\n",
        "            directory = 'Training/'\n",
        "        elif Data == \"test\":\n",
        "            directory = 'Testing/'\n",
        "\n",
        "        folder_list = natsorted(listdir(directory))\n",
        "        folder_list = folder_list[:-1]\n",
        "        flist = []\n",
        "        label_list = []\n",
        "        for subfolder in folder_list:\n",
        "          subfiles = natsorted(listdir(directory+subfolder))\n",
        "          subfiles = subfiles[:-1]\n",
        "          for subfile in subfiles:\n",
        "            flist.append(directory+subfolder+'/'+subfile)\n",
        "            label_list.append(int(subfolder))\n",
        "        \n",
        "        self.images = [Image.open(f) for f in flist]\n",
        "        self.labels = torch.Tensor(label_list).long()\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "         image = self.images[idx]\n",
        "         label = self.labels[idx]\n",
        "         if self.transform:\n",
        "             image = self.transform(image)\n",
        "         return image, label"
      ],
      "metadata": {
        "id": "VSFA3YsepfUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0omjtv5bvov"
      },
      "source": [
        "dataset = BL_Dataset('train', transforms.Compose([transforms.ToTensor(),\n",
        "                                                 transforms.Resize((32,32))\n",
        "                                                 ]))\n",
        "test_dataset = BL_Dataset('test', transforms.Compose([transforms.ToTensor(),\n",
        "                                                      transforms.Resize((32,32))\n",
        "                                                     ]))\n",
        "train_dataset, validation_dataset = random_split(dataset, [round(.80*len(dataset)),\n",
        "                                                           int(.20*len(dataset))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlHaHn1at00r"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=64)\n",
        "validation_dataloader = DataLoader(validation_dataset, shuffle=True, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image samples"
      ],
      "metadata": {
        "id": "AvBGOiJsroj-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "JQ16L4dfScry",
        "outputId": "a1d751fe-a7c1-470c-d384-f7f37340e5d3"
      },
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "data = iter(train_dataloader)\n",
        "for n in range(9):\n",
        "    ax = plt.subplot(3, 3, n+1)\n",
        "    image, labels = next(data)\n",
        "    img = image[0].permute(1, 2, 0).squeeze()\n",
        "    plt.imshow(img.numpy())\n",
        "    plt.title('Label:' + str([int(labels[0])]))\n",
        "    plt.axis('off')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90vCzVPCHGrH"
      },
      "source": [
        "# Task 1: Train two deep-learning classification models on the BTSC dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW3oGRRzFeuZ"
      },
      "source": [
        "##1-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1zVkJnt0nTh"
      },
      "source": [
        "#VGG16\n",
        "VGG16 = vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0UB2ea0w-I"
      },
      "source": [
        "VGG16.classifier._modules['6'] = nn.Linear(4096, 62)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzWre3SH4M0A"
      },
      "source": [
        "VGG16.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMmwveotFxv-"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmRo5Omlk-GM"
      },
      "source": [
        "#Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(VGG16.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "epoch_num = 10\n",
        "training_loss_plot = []\n",
        "training_accuracy_plot = []\n",
        "val_loss_plot = []\n",
        "val_accuracy_plot = []\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        \n",
        "        inputs, labels = data\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = VGG16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "           \n",
        "    training_loss_plot.append(running_loss)\n",
        "    training_accuracy_plot.append(correct/total)\n",
        "\n",
        "    #validation        \n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(validation_dataloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          \n",
        "          inputs, labels = data\n",
        "          labels = labels.type(torch.LongTensor)\n",
        "          inputs, labels = inputs.cuda(), labels.cuda()\n",
        "          \n",
        "          # forward \n",
        "          outputs = VGG16(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item() \n",
        "        \n",
        "    val_loss_plot.append(running_loss)\n",
        "    val_accuracy_plot.append(correct/total)\n",
        "print('Finished Training')\n",
        "print(\"validation \", val_accuracy_plot[epoch_num -1],\"training\", training_accuracy_plot[epoch_num-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLwhgZ8FtLso"
      },
      "source": [
        "VGG16.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VatgD8XhF5nh"
      },
      "source": [
        "###plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIvNbcqowvdY"
      },
      "source": [
        "#VGG16 plot\n",
        "plt.plot(training_loss_plot)\n",
        "plt.plot(val_loss_plot)\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.show()\n",
        "plt.plot(training_accuracy_plot)\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.plot(val_accuracy_plot)\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.title('Training and validation accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07a5GPaBF-XF"
      },
      "source": [
        "###Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9QAKSpY211e"
      },
      "source": [
        "#Test\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "      images, labels = data\n",
        "      labels = labels.type(torch.LongTensor)\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "      outputs = VGG16(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of the network on the test images: %f %%' % (\n",
        "100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSIJwd7jGJqn"
      },
      "source": [
        "##2-ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY2VSaTu-Koh"
      },
      "source": [
        "#ResNet50\n",
        "ResNet50 = torchvision.models.resnet50(pretrained = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNlsyOjyg8Gr"
      },
      "source": [
        "ResNet50._modules['6'] = nn.Linear(4096, 62)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuV-bCkvGODu"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2JtjGQiI7x"
      },
      "source": [
        "#Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ResNet50.parameters(), lr=0.001) #, momentum=0.9)\n",
        "\n",
        "epoch_num = 10\n",
        "training_loss_plot = []\n",
        "training_accuracy_plot = []\n",
        "val_loss_plot = []\n",
        "val_accuracy_plot = []\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        \n",
        "        inputs, labels = data\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        model = ResNet50\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "           model.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        outputs = ResNet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "           \n",
        "    training_loss_plot.append(running_loss)\n",
        "    training_accuracy_plot.append(correct/total)\n",
        "\n",
        "    #validation        \n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(validation_dataloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          \n",
        "          inputs, labels = data\n",
        "          labels = labels.type(torch.LongTensor)\n",
        "          inputs, labels = inputs.cuda(), labels.cuda()\n",
        "          \n",
        "          outputs = ResNet50(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item() \n",
        "        \n",
        "    val_loss_plot.append(running_loss)\n",
        "    val_accuracy_plot.append(correct/total)\n",
        "print('Finished Training')\n",
        "print(\"validation \", val_accuracy_plot[epoch_num -1],\"training\", training_accuracy_plot[epoch_num-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fp-vJ3sAJX"
      },
      "source": [
        "ResNet50.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_dRyoZBGSs6"
      },
      "source": [
        "###Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bDOzX_yiYTQ"
      },
      "source": [
        "#ResNet50 plot\n",
        "plt.plot(training_loss_plot)\n",
        "plt.plot(val_loss_plot)\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.show()\n",
        "plt.plot(training_accuracy_plot)\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.plot(val_accuracy_plot)\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.title('Training and validation accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQOh1agmGVeJ"
      },
      "source": [
        "###Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z7TW_BAicFC"
      },
      "source": [
        "#Test\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "      images, labels = data\n",
        "      labels = labels.type(torch.LongTensor)\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "      outputs = ResNet50(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of the network on the test images: %f %%' % (\n",
        "100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi-fi5x8HavF"
      },
      "source": [
        "#Task 2: non-targeted white-box evasion attacks against the deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afUY7CuYGpOh"
      },
      "source": [
        "##1-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AplnmzT-i7rz"
      },
      "source": [
        "epsilons = [0, 5/255,  10/255, 20/255, 50/255]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vhb26cXHAdB"
      },
      "source": [
        "###FSGM-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csT_osBT32Uz"
      },
      "source": [
        "#FSGM- VGG16\n",
        "correct = 0\n",
        "total = 0\n",
        "accuracies_FSGM =[]\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    # labels = labels.type(torch.LongTensor)\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = fast_gradient_method(VGG16, images, epsilon, np.inf)\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_FSGM.append(np.mean(accuracy))\n",
        "print(accuracies_FSGM)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SC9NEYwHMpT"
      },
      "source": [
        "###PGD-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZwt105BgTH4"
      },
      "source": [
        "#PGD-VGG16\n",
        "correct = 0\n",
        "total = 0\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    # labels = labels.type(torch.LongTensor)\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = VGG16, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf)\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_PGD.append(np.mean(accuracy))\n",
        "print(accuracies_PGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWITd3w5Aq7-"
      },
      "source": [
        "###DeepFool-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhPsic8Adto"
      },
      "source": [
        "#DeepFool\n",
        "\n",
        "VGG16T = PyTorchClassifier(model=VGG16, loss=nn.CrossEntropyLoss(), nb_classes=62, input_shape=(3, 32, 32), device_type='gpu')\n",
        "accuracies_DF = []\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_attack = 0\n",
        "epsilons = [0, 5/255, 10/255, 20/255, 50/255]\n",
        "for epsilon in tqdm(epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = DeepFool(VGG16T, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CW2-VGG16"
      ],
      "metadata": {
        "id": "hwbq2TZhk1ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2\n",
        "VGG16T = PyTorchClassifier(model=VGG16, loss=nn.CrossEntropyLoss(), nb_classes=62, input_shape=(3, 32, 32), device_type='gpu')\n",
        "accuracies_CW2 = []\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_attack = 0\n",
        "for k in tqdm(kap) :\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = CarliniL2Method(VGG16T, confidence = k, \n",
        "                                         learning_rate = 0.01,\n",
        "                                         max_iter = 7,\n",
        "                                         batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)\n"
      ],
      "metadata": {
        "id": "oM7ESbZDsvJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDUyn_KaHS-A"
      },
      "source": [
        "###VGG16-FSGM_PGD_DeepFool plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Cqk3bZvwwD"
      },
      "source": [
        "#VGG16-FSGM-PGD plot\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies_FSGM, \"o-\")\n",
        "plt.plot(epsilons, accuracies_PGD, \"o-\")\n",
        "plt.plot(epsilons, accuracies_DF, \"o-\")\n",
        "\n",
        "\n",
        "plt.legend(['FSGM', 'PGD' , 'DeepFool'])\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VGG16-CW2 plot"
      ],
      "metadata": {
        "id": "C0Aj0Gftk_Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(kap, accuracies_CW2, \"o-\")\n",
        "plt.legend(['CW2'])\n",
        "plt.title(\"Accuracy vs confidence\")\n",
        "plt.xlabel(\"confidence\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kj7hBU9kZo6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEurcMLEHamI"
      },
      "source": [
        "###FSGM-VGG16 image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlz_PQwozcwB"
      },
      "source": [
        "#FSGM- VGG16- image plot\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "plt.figure(figsize=(20,15), constrained_layout=True)\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for data in subsest_dataloader:\n",
        "  for epsilon in epsilons: \n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = fast_gradient_method(VGG16, images, epsilon, np.inf)\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(6, 3, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    \n",
        "    plt.axis('off')\n",
        "    cnt +=1\n",
        "  break\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4nLq012IAQg"
      },
      "source": [
        "##2- ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR2JMAB3IJnY"
      },
      "source": [
        "###FSGM-ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTWAEf78iAMp"
      },
      "source": [
        "#FGSM- ResNet50\n",
        "total = 0\n",
        "correct = 0\n",
        "accuracies =[]\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = fast_gradient_method(ResNet50, images, epsilon, np.inf)\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies.append(np.mean(accuracy))\n",
        "print(accuracies)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN_BeD80IOYk"
      },
      "source": [
        "###PGD-ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfmUp6i1iz0E"
      },
      "source": [
        "#PGD- ResNet50\n",
        "correct = 0\n",
        "total = 0\n",
        "accuracies =[]\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = ResNet50, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf)\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies.append(np.mean(accuracy))\n",
        "print(accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DeepFool\n",
        "accuracies_DF = []\n",
        "ResNet50_RS = PyTorchClassifier(model=ResNet50, loss=nn.CrossEntropyLoss(), nb_classes=62, input_shape=(3, 32, 32), device_type='gpu')\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_attack = 0\n",
        "for epsilon in tqdm(epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = DeepFool(ResNet50_RS, epsilon= epsilon, batch_size = 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)\n"
      ],
      "metadata": {
        "id": "rmHeMSnYXpnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2\n",
        "accuracies_CW2 = []\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_attack = 0\n",
        "for k in tqdm(kap):\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = CarliniL2Method(ResNet50_RS, confidence = k, learning_rate = 0.001, max_iter = 7, batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)\n"
      ],
      "metadata": {
        "id": "TBU4j6cAYDpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0cur5QFIRqT"
      },
      "source": [
        "###DF-FSGM-PGD-ResNet50 plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHjmufxlnhp"
      },
      "source": [
        "\n",
        "plt.plot(epsilons, accuracies_FSGM, \"o-\")\n",
        "plt.plot(epsilons, accuracies_PGD, \"o-\")\n",
        "plt.plot(epsilons, accuracies_DF, \"o-\")\n",
        "\n",
        "plt.legend(['FSGM', 'PGD', 'DF'])\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CW2-ResNet50 plot"
      ],
      "metadata": {
        "id": "o6VPpN80lL5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(kap, accuracies_CW2, \"o-\")\n",
        "plt.legend(['CW2'])\n",
        "plt.title(\"Accuracy vs confidence\")\n",
        "plt.xlabel(\"confidence\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XMeuNwgxZ6Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVdURyplIWJJ"
      },
      "source": [
        "###FSGM-ResNet50 image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qICUzjFfHogX"
      },
      "source": [
        "#FSGM- ResNet50- image plot\n",
        "sub_dataset = Subset(test_dataset, list(range(100)))\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "plt.figure(figsize=(20,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for data in subsest_dataloader:\n",
        "  for epsilon in epsilons: \n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = ResNet50, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf)\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(6, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "  break\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnROA09gGi9c"
      },
      "source": [
        "# Task 3: Implement targeted white-box evasion attacks against the deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXJViMLPfwL0"
      },
      "source": [
        "##1- Targeted PGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28GXzw93Lddp"
      },
      "source": [
        "###VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZIPtUURfp2G"
      },
      "source": [
        "#### Accuracy on Label 21- Stop sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uALxQ05JlnW5"
      },
      "source": [
        "#PGD-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list1 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list1.append(i)\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list1)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = VGG16, x =images,\n",
        "                                                    eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_PGD.append(np.mean(accuracy))\n",
        "print(accuracies_PGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmKi_EpvfkHN"
      },
      "source": [
        "#### Accuracy on Label 32- speed limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANvm3_grfOdk"
      },
      "source": [
        "#PGD-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list2 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list2.append(i)\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list2)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = VGG16, x =images,\n",
        "                                                    eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_PGD.append(np.mean(accuracy))\n",
        "print(accuracies_PGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8FbGSwdKkaS"
      },
      "source": [
        "####PGD- VGG16 image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70F299THgbRD"
      },
      "source": [
        "#PGD- VGG16- image plot\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list1)\n",
        "subset_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subset_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = VGG16, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(5, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRz-nKUXK-_a"
      },
      "source": [
        "### ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZpAofx3Luqs"
      },
      "source": [
        "#### Accuracy on label 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC4cll5mPdcB"
      },
      "source": [
        "#ResNet50- PGD\n",
        "total = 0\n",
        "correct = 0\n",
        "list4 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list4.append(i)\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list4)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = ResNet50, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_PGD.append(np.mean(accuracy))\n",
        "print(accuracies_PGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYzzqz0OL-b3"
      },
      "source": [
        "#### Accuracy on Label 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkgrlxvIkJKw"
      },
      "source": [
        "#ResNet50- PGD\n",
        "total = 0\n",
        "correct = 0\n",
        "list5 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list5.append(i)\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list5)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = ResNet50, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_PGD.append(np.mean(accuracy))\n",
        "print(accuracies_PGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwBcnQ2SMDBi"
      },
      "source": [
        "####PGD- ResNet50 Image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xAnWeQ-QHwK"
      },
      "source": [
        "#ResNet50- PGD- Image plot\n",
        "accuracies_PGD =[]\n",
        "sub_dataset = Subset(test_dataset, list4)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  # skip = True\n",
        "  for data in subsest_dataloader:\n",
        "    #if skip:\n",
        "    #  skip = False\n",
        "    #  continue\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = projected_gradient_descent(model_fn = ResNet50, x =images, eps = epsilon, eps_iter =2.5*epsilon/60, nb_iter =60, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(6, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paoOO20WMOP4"
      },
      "source": [
        "##2- Targeted FGSM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQt0Nf08MVyk"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45c4XFW7MbBP"
      },
      "source": [
        "#### Accuracy on label 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lRn0HlTQbY-"
      },
      "source": [
        "#VGG16- FGSM\n",
        "total = 0\n",
        "correct = 0\n",
        "list6 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list6.append(i)\n",
        "accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list6)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = VGG16, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_FGSM.append(np.mean(accuracy))\n",
        "print(accuracies_FGSM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09o0-oqCkcOC"
      },
      "source": [
        "#### Accuracy on Label 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luH0mnoVkTUI"
      },
      "source": [
        "#VGG16- FGSM\n",
        "total = 0\n",
        "correct = 0\n",
        "list7 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list7.append(i)\n",
        "accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list7)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = VGG16, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_FGSM.append(np.mean(accuracy))\n",
        "print(accuracies_FGSM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSB8Ss1IMocD"
      },
      "source": [
        "#### FGSM-VGG16 image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lGxKdmaRceU"
      },
      "source": [
        "#VGG16- FGSM- Image plot\n",
        "accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list6)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  # skip = True\n",
        "  for data in subsest_dataloader:\n",
        "    #if skip:\n",
        "    #  skip = False\n",
        "    #  continue\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = VGG16, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(6, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neuVRWHUM5hs"
      },
      "source": [
        "###ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fENh95nzM9O-"
      },
      "source": [
        "####Accuracy on label 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azc9bhM4SMSa"
      },
      "source": [
        "#ResNet50- FGSM\n",
        "correct = 0\n",
        "total = 0\n",
        "list8 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list8.append(i)\n",
        "accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list8)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = ResNet50, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_FGSM.append(np.mean(accuracy))\n",
        "print(accuracies_FGSM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iXfRyGjkwvY"
      },
      "source": [
        "####Accuracy on label 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBwL8pPmkySM"
      },
      "source": [
        "#ResNet50- FGSM\n",
        "correct = 0\n",
        "total = 0\n",
        "list9 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list9.append(i)\n",
        "accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list9)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = ResNet50, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_FGSM.append(np.mean(accuracy))\n",
        "print(accuracies_FGSM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvDNPPJoNbIH"
      },
      "source": [
        "#### FSGM-ResNet50 image plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOirJa09_o--"
      },
      "source": [
        "#ResNet50- FGSM- Image plot\n",
        "#accuracies_FGSM =[]\n",
        "sub_dataset = Subset(test_dataset, list8)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  skip = True\n",
        "  for data in subsest_dataloader:\n",
        "    if skip:\n",
        "      skip = False\n",
        "      continue\n",
        "    images, labels = data\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = fast_gradient_method(model_fn = ResNet50, x =images, eps = epsilon, norm = np.inf, y = labels_f,  targeted = True )\n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(6, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Targeted DeepFool"
      ],
      "metadata": {
        "id": "466oXafMCBAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VGG16"
      ],
      "metadata": {
        "id": "1G3al-oYCHNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Acuuracy on label 21"
      ],
      "metadata": {
        "id": "803RQ3FJCRHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list10 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list10.append(i)\n",
        "accuracies_DF =[]\n",
        "sub_dataset = Subset(test_dataset, list10)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(VGG16T, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)"
      ],
      "metadata": {
        "id": "klHt0NjhCUK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy on label 32"
      ],
      "metadata": {
        "id": "K1FU5DgkDlGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list11 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list11.append(i)\n",
        "accuracies_DF =[]\n",
        "sub_dataset = Subset(test_dataset, list11)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(VGG16T, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)"
      ],
      "metadata": {
        "id": "3246-Pt-CLbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DF-VGG16 image plot"
      ],
      "metadata": {
        "id": "u8nFSL-Almjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF- VGG16- image plot\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list10)\n",
        "subset_dataloader = DataLoader(sub_dataset, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(VGG16T, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(5, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "  \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "MUTjvy1jJpUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ResNet50"
      ],
      "metadata": {
        "id": "AVAM4pogKRba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy on label 21"
      ],
      "metadata": {
        "id": "hUFVBq8EKV-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF-ResNet50\n",
        "total = 0\n",
        "correct = 0\n",
        "list12 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list12.append(i)\n",
        "accuracies_DF =[]\n",
        "sub_dataset = Subset(test_dataset, list12)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(ResNet50_RS, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)"
      ],
      "metadata": {
        "id": "fRZiR029KUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy on label 32"
      ],
      "metadata": {
        "id": "TY-uCASvK0xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF-ResNet50\n",
        "total = 0\n",
        "correct = 0\n",
        "list13 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list13.append(i)\n",
        "accuracies_DF =[]\n",
        "sub_dataset = Subset(test_dataset, list13)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(ResNet50_RS, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_DF.append(np.mean(accuracy))\n",
        "print(accuracies_DF)"
      ],
      "metadata": {
        "id": "zXNkTG2gK4k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DF-ResNet50 image plot"
      ],
      "metadata": {
        "id": "tPC2srGHlwR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DF- ResNet50- image plot\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list12)\n",
        "subset_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for epsilon in tqdm (epsilons):\n",
        "  print(epsilon)\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = DeepFool(ResNet50_RS, epsilon= epsilon, batch_size= 64, max_iter = 50).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(5, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('epsilon: '+ str(epsilon)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "  \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "nAnFJt7sXhXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Targeted CW2"
      ],
      "metadata": {
        "id": "FfnblnofYCAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VGG16"
      ],
      "metadata": {
        "id": "LImBkGeeYErZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy for label 21\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PFu5GyjYGMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list14 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list14.append(i)\n",
        "accuracies_CW2 =[]\n",
        "sub_dataset = Subset(test_dataset, list14)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "for k in tqdm (kap):\n",
        "  \n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(VGG16T, confidence = k, \n",
        "                                         learning_rate = 0.01,\n",
        "                                         max_iter = 7,\n",
        "                                         batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)"
      ],
      "metadata": {
        "id": "I5Wqq01ZYQz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy for label 32"
      ],
      "metadata": {
        "id": "6wuI1txBZLFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2-VGG16\n",
        "total = 0\n",
        "correct = 0\n",
        "list15 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list15.append(i)\n",
        "accuracies_CW2 =[]\n",
        "sub_dataset = Subset(test_dataset, list15)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "\n",
        "for k in tqdm (kap):\n",
        "  \n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(VGG16T, confidence = k, \n",
        "                                         learning_rate = 0.01,\n",
        "                                         max_iter = 7,\n",
        "                                         batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)"
      ],
      "metadata": {
        "id": "9YSKoKqaX6iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CW2-VGG16 image plot"
      ],
      "metadata": {
        "id": "ZmVUs-Fxl2W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2- VGG16- image plot\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list14)\n",
        "subset_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "\n",
        "for k in tqdm (kap):\n",
        " \n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(VGG16T, confidence = k, \n",
        "                                         learning_rate = 0.01,\n",
        "                                         max_iter = 7,\n",
        "                                         batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = VGG16(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(5, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('confidence: '+ str(k)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "  \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "00HG0UJGZcy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ResNet50"
      ],
      "metadata": {
        "id": "X6hrYbtDaJYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy for label21"
      ],
      "metadata": {
        "id": "jhpWNSsvaLTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2-ResNet50\n",
        "total = 0\n",
        "correct = 0\n",
        "list16 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 21:\n",
        "    list16.append(i)\n",
        "accuracies_CW2 =[]\n",
        "sub_dataset = Subset(test_dataset, list16)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "kap = [0, 0.1, 0.5, 1.0]\n",
        "\n",
        "for k in tqdm (kap):\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(ResNet50_RS, confidence = k, learning_rate = 0.001, max_iter = 7, batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)"
      ],
      "metadata": {
        "id": "uImlQj1aaPD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Accuracy for label 32"
      ],
      "metadata": {
        "id": "ZOCJUliZbIW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2-ResNet50\n",
        "total = 0\n",
        "correct = 0\n",
        "list17 = []\n",
        "for i in range (len(test_dataset)):\n",
        "  if test_dataset[i][1] == 32:\n",
        "    list17.append(i)\n",
        "accuracies_CW2 =[]\n",
        "sub_dataset = Subset(test_dataset, list17)\n",
        "subsest_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "for k in tqdm (kap):\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(ResNet50_RS, confidence = k, learning_rate = 0.001, max_iter = 7, batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_f).sum().item()\n",
        "    accuracy.append(correct/total)\n",
        "\n",
        "  accuracies_CW2.append(np.mean(accuracy))\n",
        "print(accuracies_CW2)"
      ],
      "metadata": {
        "id": "qXijLo4ubLD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CW2-ResNet50 image plot"
      ],
      "metadata": {
        "id": "RGjcL3Lfl7uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW2- ResNet50- image plot\n",
        "\n",
        "sub_dataset = Subset(test_dataset, list16)\n",
        "subset_dataloader = DataLoader(sub_dataset, batch_size=64)\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "cnt =1\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.9    # the right side of the subplots of the figure\n",
        "bottom = 0.5   # the bottom of the subplots of the figure\n",
        "top = 1.5    # the top of the subplots of the figure\n",
        "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.5\n",
        "plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
        "\n",
        "for k in tqdm (kap):\n",
        "  accuracy = []\n",
        "  for data in subsest_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels.cuda()\n",
        "    labels_f = torch.ones_like(labels).cuda()\n",
        "    labels_f = labels_f.type(torch.LongTensor).cuda()\n",
        "    adversarial_images = CarliniL2Method(ResNet50_RS, confidence = k, learning_rate = 0.001, max_iter = 7, batch_size = 64).generate(images.numpy())\n",
        "    adversarial_images = torch.tensor(adversarial_images).cuda()    \n",
        "    outputs = ResNet50(adversarial_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    plt.subplot(5, 2, cnt)\n",
        "    img = adversarial_images.cpu().detach().numpy()[0]\n",
        "    img = np.transpose(img, [1,2,0])\n",
        "    plt.imshow(img)\n",
        "    label = predicted.cpu().detach().numpy()[0]\n",
        "    plt.title('confidence: '+ str(k)+ '\\n' + 'predicted label: ' + str([int(labels[0])]))\n",
        "    cnt +=1\n",
        "    break\n",
        "  \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "UqDPI8UdbntN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}